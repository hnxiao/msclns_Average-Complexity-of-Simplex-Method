
\documentclass{article}

\setlength{\oddsidemargin}{0.05 in}
\setlength{\evensidemargin}{-0.05 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{9.5 in}
\setlength{\headsep}{0.25 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,amssymb,enumerate,graphicx}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

\newcommand{\tran}{^{\mbox{\tiny $\top$}}}
\newcommand{\tleq}{^{\mbox{\tiny $\leqslant$}}}
\newcommand{\teq}{^{\mbox{\tiny $=$}}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[2]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
       \vbox{\vspace{2mm}
         \hbox {\leftline{\Large LECTURE #1: \hfill}}
         \vspace{3mm}
         \hbox {\leftline{\Large #2 \hfill}}
         \vspace{4mm}
         \hrule
         \vspace{3mm}
         \hbox to 6.5in { {{\large Theory of linear and integer programming}  \hfill Dec. 2012} }
         \vspace{3mm}
        }
   \end{center}
   \markboth{LECTURE #1: #2}{LECTURE #1: #2}
   \pagenumbering{arabic}
   \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\it Proof.}}{ \hfill $\square$}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\def\R{{\mathbb R}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{11}{On average running time of the simplex method}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\textbf{Crossreference }

simplex method

complexity


\section{Fast recap: the simplex method}
What is simplex method? The geometrical interpretation.

phase I

phase II

Since Phase I works in a similar manner to Phase II, and Phase II admits a better geometrical explanation, we concentrate on Phase II.
\section{Shadow-vertex pivot rule}
The simplex method relies heavily on the pivot rule. A different pivot rule leads to a 'variant' of the simplex method. There are many different rules such as...  The shadow-vertex pivot rule works extremely well in theoretical studies and will be used in the following analysis, we explain it in detail.

Shadow-vertex pivot rule:?

Geometric interpretation of the shadow-vertex pivot rule:

Properties of the shadow-vertex rule:


\section{Efficiency of algorithms}
Engineers:

Theorists:

Reason for discrepancy:

How to make theory more consistent with practice? More compatible with practice? Find a more realistic performance measure.

Average-case analysis:


\section{The average-running time of the simplex method}
Sign-invariant model(SIM) 

It's extremely simple and only relies on a finite number of reflections and symmetries. In analysis it's more sufficient to consider a somehow relaxed version of sign-in-variance, the so-called flipping model.
$\max\{\pm c^T x|a_1^T\leqslant \geqslant \beta_1; \dots ; a_m^T\leqslant \geqslant \beta_m\}$. Here $\leqslant\geqslant$ indicates that one of the relations $\leqslant$ or $\geqslant$ is valid in the formulation of the instance. And we independently determine the m directions of the relations, each one with probability 1/2 for $\geqslant$ and with probability 1/2 for $\leqslant$. The we generate exactly $2^{m+1}$ problem instance out of the data set $A, b, c, \bar{c}$.  The idea of averaging is to solve all $2^{m+1}$ instances, to sum up the required pivot steps and to divide by the number of instances.

Here we consider/ we restrict ourselves to a simplified model which captures all the difficulty /complexity in polyhedral aspects

\section{average running time}
\begin{theorem}
The class of LP-program given as $\max\{c^\top x|Ax\leqslant b\}$, can be solved with the simplex method, using the shadow vertex pivot rule, in at most $\frac{1}{2}n$ pivot iterations on the average, under any probability measure satisfying(47).
\end{theorem}
\begin{proof}
Let the LP-program $\max\{c^\top x| Ax\leqslant b\}$ be given, together with a vertex (extreme point/basic feasible solution) $x_0$ of $\{x| Ax\leqslant b\}$ and a vector $\bar{c}$ such that $x_0$ maximizes $\bar{c}^\top x$ over $Ax\leqslant b$. Let $m$ and $n$ be the numbers of rows and columns of $A$.  

Let $z_1,\dots,z_t$ be those vectors in $\R^n$ which can be determined by some choice of $n$ linearly independent equations from $Ax=b$. So $t=\binom{m}{n}$ with probability 1. Consider the class $\mathcal{L}$ of LP-problems $\max\{\hat{c}^\top x|\hat{A}x\leqslant \hat{b}\}$ which arise from $\max\{c^\top x|Ax\leqslant b\}$ by reversing some (or none) of the inequality signs and/or replacing $c$ by $-c$, and for which
\begin{equation}
\max\{\bar{c}^\top x|\hat{A}x\leqslant \hat{b}\}
\end{equation}
is finite. We claim $\lvert \mathcal{L} \rvert=2\binom{m}{n}$. Indeed, by (47) (the probabilistic measure condition), with probability 1, each $\max\{\bar{c}^\top x|\hat{A}x\leqslant\hat{b}\}$ is uniquely attained by a vertex of $\hat{A}x\leqslant \hat{b}$\footnote{This observation comes from the definition of class $\mathcal{L}$, which requires that for all instances in $\mathcal{L}$, $\max\{\bar{c}^\top x|\hat{A}x\leqslant \hat{b}\}$ is finite.}, and hence by one of the vectors $z_i$. Moreover, for each $z_i$ there is exactly \emph{one} choice of $\hat{A}x\leqslant \hat{b}$ for which $\max\{\bar{c}^\top x|\hat{A}x\leqslant \hat{b}\}$ is attained by $z_i$. [Since, with probability 1, there are exactly $n$ inequalities in $\hat{A}x\leqslant \hat{b}$, say $\hat{A}^\prime x\leqslant \hat{b}^\prime$, which are satisfied by $z_i$ with equality. Hence the inequality sign is strict in the other $m-n$ inequalities, and therefore we can not reverse the sign. Moreover, $\bar{c}$ must be in the cone generated by the rows of $\hat{A}^\prime$\footnote{$\bar{c}$ is the non-negative combination of all tight(active) constraints). c.f. p93 in schrijver's book, LP-Duality Geometrically or Fakas' Lemma. As to 'cone', please refer to its def ;}, and hence also here the signs\footnote{Since $\bar{c}$ is fixed, and is a non-negative combination of all directions of tight constraints, so all this tight constraints can not be flipped (reversed) otherwise $\bar{c}$ will no longer be in the cones generated by all the directions of these constraints} are uniquely determined.] So to $z_i$ there correspond the programs $\max\{cx|\hat{A}x\leqslant\hat{b}\}$ and $\max\{-cx|\hat{A}x\leqslant \hat{b}\}$\footnote{The only 2 relations that are revertible/flip-able in $\mathcal{L}$ }. Therefore, $\lvert \mathcal{L}\rvert=\binom{m}{n}$.

Next consider the class of edges and rays formed by the systems $\hat{A}x\leq\hat{b}$. Each set of $n-1$ equations from $Ax=b$ gives a line(1-dimensional affine subspace) in $\R^n$, containing $m-n+1$ of $z_i$. The $z_i$ subdivide this line into $m-n$ edges and two rays.

Let $l$ be such a line, and let $z_i$ and $z_j$ be two neighboring points on $l$(i.e. the line segment $\overline{z_i z_j}$ contains no other points from $z_1,\dots,z_t$). Then the edge $\overline{z_i z_j}$ is traversed in at most (in fact, exactly) one of the programs in $\mathcal{L}$. For suppose $\overline{z_i z_j}$ is traversed in more than one of these programs $\max\{\hat{c}^\top x|\hat{A}x\leqslant \hat{b}\}$. Then starting with an arbitrary feasible program in $\mathcal{L}$, we can always obtain a new feasible program in $\mathcal{L}$ by reverting or flipping operation. However, it turns out that for any feasible program from $\mathcal{L}$, neither the constrains nor the objective function is revertible.
\end{proof}

\section*{References}
\beginrefs
\bibentry{CW87}{\sc D.~Coppersmith} and {\sc S.~Winograd},
``Matrix multiplication via arithmetic progressions,''
{\it Proceedings of the 19th ACM Symposium on Theory of Computing},
1987, pp.~1--6.
\endrefs

% **** THIS ENDS THE EXAMPLES. DON'T DELETE THE FOLLOWING LINE:

\end{document}







